{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: [Guanghua Zha]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2019F/blob/master/homework/HM3/HM3.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 56s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    r=[]\n",
    "    for item in y:\n",
    "        a=numpy.zeros(10)\n",
    "        a[item]=1\n",
    "        r.append(a)\n",
    "    return numpy.array(r)\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_85 (Conv2D)           (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 30, 30, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 30, 30, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 15, 15, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 15, 15, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 15, 15, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_88 (Conv2D)           (None, 13, 13, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 13, 13, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 13, 13, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_89 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_90 (Conv2D)           (None, 4, 4, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 2,742,282\n",
      "Trainable params: 2,739,466\n",
      "Non-trainable params: 2,816\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 2.0686 - acc: 0.2120 - val_loss: 2.1290 - val_acc: 0.2892\n",
      "Epoch 2/10\n",
      "40000/40000 [==============================] - 17s 413us/step - loss: 1.6522 - acc: 0.3630 - val_loss: 1.5812 - val_acc: 0.3903\n",
      "Epoch 3/10\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 1.4789 - acc: 0.4433 - val_loss: 1.3132 - val_acc: 0.5290\n",
      "Epoch 4/10\n",
      "40000/40000 [==============================] - 19s 481us/step - loss: 1.3524 - acc: 0.5169 - val_loss: 1.1780 - val_acc: 0.6074\n",
      "Epoch 5/10\n",
      "40000/40000 [==============================] - 17s 431us/step - loss: 1.2212 - acc: 0.5861 - val_loss: 1.4523 - val_acc: 0.5161\n",
      "Epoch 6/10\n",
      "40000/40000 [==============================] - 17s 435us/step - loss: 1.1367 - acc: 0.6236 - val_loss: 0.9772 - val_acc: 0.6637\n",
      "Epoch 7/10\n",
      "40000/40000 [==============================] - 17s 426us/step - loss: 1.0657 - acc: 0.6563 - val_loss: 1.0815 - val_acc: 0.6668\n",
      "Epoch 8/10\n",
      "40000/40000 [==============================] - 18s 460us/step - loss: 1.0184 - acc: 0.6815 - val_loss: 0.9870 - val_acc: 0.6881 loss: 1.0189\n",
      "Epoch 9/10\n",
      "40000/40000 [==============================] - 17s 422us/step - loss: 0.9701 - acc: 0.7008 - val_loss: 1.1769 - val_acc: 0.6309\n",
      "Epoch 10/10\n",
      "40000/40000 [==============================] - 17s 424us/step - loss: 0.9412 - acc: 0.7177 - val_loss: 0.9374 - val_acc: 0.6954\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_tr, y_tr, batch_size=64, epochs=10, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<Compile your model again (using the same hyper-parameters)>\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "50000/50000 [==============================] - 21s 427us/step - loss: 0.9372 - acc: 0.7188\n",
      "Epoch 2/10\n",
      "50000/50000 [==============================] - 20s 401us/step - loss: 0.9094 - acc: 0.7340\n",
      "Epoch 3/10\n",
      "50000/50000 [==============================] - 20s 400us/step - loss: 0.8771 - acc: 0.7444\n",
      "Epoch 4/10\n",
      "50000/50000 [==============================] - 20s 409us/step - loss: 0.8557 - acc: 0.7534\n",
      "Epoch 5/10\n",
      "50000/50000 [==============================] - 20s 390us/step - loss: 0.8381 - acc: 0.7603\n",
      "Epoch 6/10\n",
      "50000/50000 [==============================] - 20s 396us/step - loss: 0.8318 - acc: 0.7692\n",
      "Epoch 7/10\n",
      "50000/50000 [==============================] - 20s 397us/step - loss: 0.8349 - acc: 0.7745\n",
      "Epoch 8/10\n",
      "50000/50000 [==============================] - 21s 415us/step - loss: 0.8132 - acc: 0.7750\n",
      "Epoch 9/10\n",
      "50000/50000 [==============================] - 20s 410us/step - loss: 0.8532 - acc: 0.7773\n",
      "Epoch 10/10\n",
      "50000/50000 [==============================] - 20s 398us/step - loss: 0.8347 - acc: 0.7788\n"
     ]
    }
   ],
   "source": [
    "#<Train your model on the entire training set (50K samples)>\n",
    "#<Use (x_train, y_train_vec) instead of (x_tr, y_tr)>\n",
    "#<Do NOT use the validation_data option (because now you do not have validation data)>\n",
    "\n",
    "history = model.fit(x_train, y_train_vec, batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 244us/step\n",
      "loss = 0.7465812520027161\n",
      "accuracy = 0.7843000292778015\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
